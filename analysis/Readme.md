# Readme


20200813
本文件夹下是测试 open AI gym 环境的分析测试，分析项目包括以下：

- 每个游戏的随机性：rand.py
    30 组相同随机种子、相同网络、相同初始帧、测5次，得分是否完全一致
- 结束机制
    
- 动作空间大小: action.py

- 起始帧敏感程度
    5 组相同随机种子、相同网络、不同随机帧（目前是等距采样5组）测试30次，得分是否完全一致

## 随机帧实验笔记
不同随机帧，其他全部相同。主要观察5组均值之间是否相等（对随机帧是否敏感），每组30次结果之间的方差是否为0（是否存在其他随机性，前一个结果是否可信），一共测试了 10 个游戏。

1. 如果跑的30次结果方差为 0 而均值又不等，那么可以说明该游戏随机帧敏感。
比如 Airraid，五组随机帧均值为 [1175.0, 725.0, 1425.0, 1125.0, 1175.0]， 五组方差为 [0.0, 0.0, 0.0, 0.0, 0.0]。像这样的游戏还有 Alien，Bowling，Berzerk, Doubledunk。

2. 如果跑的30 次结果方差不为 0，也就是说存在除了随机帧、随机种子、sticky action意外的随机性，但是均值明显高低差别较大，也可以说是随机帧敏感的。需要进一步实验随机性还有可能来自哪里。比如 Beamrider 的五组随机帧 [264.0, 220.0, 352.0, 484.0, 572.0]方差为[8658.22222222222, 9680.0, 2787.839999999999, 15178.239999999998, 481.8488888888889]。

3. 方差不为 0 但每组均值相等，这个看起来像是从一个相同分布中随机采样也能得到的结果，可能是对随机帧不敏感的，也有可能是我们 agent 不够好，都是随便采样。比如 seaquest。

4. 方差为0 均值相等，说明对随机帧不敏感。还有一种就是均值全为 0，比较不了。其他几个属于这一种。

需要进一步实验，和随机种子实验对照查看。
## 随机种子实验笔记

记录主要查看：
1. 同一个随机种子跑出的 5 次结果方差是否为0（其他的已知随机性已经消除了）
    - var = 0 初步说明只和随机种子有关
    - var ≠ 0 至少说明有随机性，而且随机种子不完全可控
2. 不同组的随机种子的 5 次结果之间相似度（排序后A-B求欧式距离）
    - 30 组 = 0 的初步说明，可能游戏在 agent 所能探索到的范围中没有随机性，或我们的 agent 不是太好，或我们测试范围太小
    - 有至少一组 ≠ 0 说明，游戏至少是具有来自随机种子的随机性的。

1. 不清楚随机性来自哪里的游戏： 典型游戏 DemoAtrack 和 YarRevenge var 不为 0，同一随机种子、同一个agent、stick action已经消除、同一个初始帧，但5次组内和5组间还是有不一样，随机性到底来自哪里？
- 其中 Demo Attrack 得分还是同样几个，方差还比较小，随机性比较小。YarRevenge 每次完全不一样。
每行是一个随机种子的结果。
DemoAtrack
[205.0, 205.0, 120.0, 120.0, 205.0], 
[205.0, 205.0, 205.0, 120.0, 205.0], 
[205.0, 120.0, 120.0, 205.0, 120.0], 
[205.0, 205.0, 205.0, 120.0, 205.0], 
[205.0, 205.0, 205.0, 205.0, 120.0]
YarRevenge
 [2070.0, 3719.0, 3864.0, 3105.0, 3305.0], 
 [7617.0, 2829.0, 1932.0, 2691.0, 2898.0], 
 [3412.0, 3036.0, 3274.0, 7210.0, 2691.0], 
 [3312.0, 3888.0, 3036.0, 3274.0, 4102.0], 
 [2829.0, 2691.0, 3795.0, 2277.0, 2208.0]
2. Time Pilot 也是个很奇怪的游戏，每个随机种子的 5 次重复实验结果不一致 但是不同随机种子的结果之间是一致的。
 Time pilot 
 [[4700.0, 500.0, 500.0, 500.0, 500.0], 
 [4700.0, 500.0, 500.0, 500.0, 500.0], 
 [4700.0, 500.0, 500.0, 500.0, 500.0], 
 [4700.0, 500.0, 500.0, 500.0, 500.0], 
 [4700.0, 500.0, 500.0, 500.0, 500.0]]
3. 典型游戏 kangaroo ，组间完全一样，组内完全一样，大部分游戏属于这一种。要么是静态游戏，要么是我们 agent不好（得分全是0）。热力图如 ![](analysis/logs_randseed/Kangaroo/heatmap.png)

## Env 接口笔记

所有环境和设置可以在这里查看
https://github.com/openai/gym/blob/master/gym/envs/__init__.py

总结来说：
1. 比较简单的`ToyText`，`Algorithmic`，`Box2d`和` classics` 类各有五个游戏，每个游戏两个参数 `reward_threshold`和`max_episode_type`，其中 carpole 有两个版本，该版本都可以自己定制环境
2. Atari 类有60个游戏，（但deepmind也只最多测试57个？）。
    - 所有游戏分为  `image`和`ram`版，区别是一个提供图像状态（我们当前使用的），一个提供额外信息元组（如pitfall中是live,agent position，treasure position et. al.）。
    - 在以上两个版本中又分为四个版本，之间的区别是是否p=0.25的粘滞动作、是否确定性。
    - 其中随机版本的 frameskip 均为 1，确定性版本 frameskip = 4 (特例spaceinvader为3)。
3. Mojoco 2D 有13个游戏，其中 6 个有两个版本，Robotics 类有 25 个任务，其中有 6 个有两个版本。Robotic 任务都有奖励 'sparse', 'dense'选项可以选。

以下是环境所有的方法
```
['__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_close', '_closed', '_elapsed_seconds', '_elapsed_steps', '_ensure_no_double_wrap', '_env_closer_id', '_episode_started_at', '_max_episode_seconds', '_max_episode_steps', '_owns_render', '_past_limit', '_render', '_reset', '_seed', '_step', 'action_space', 'class_name', 'close', 'configure', 'env', 'metadata', 'monitor', 'observation_space', 'render', 'reset', 'reward_range', 'seed', 'spec', 'step', 'unwrapped']```
